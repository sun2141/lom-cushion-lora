{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9886db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… LOM Cushion LoRA Trainer (Colab ë…¸íŠ¸ë¶)\n",
    "\n",
    "# === [1] í™˜ê²½ì„¤ì • ===\n",
    "# Colab ê¸°ë³¸ torch==2.6.0, torchvision==0.21.0, torchaudio==2.6.0 ìœ ì§€\n",
    "!pip install -U torch torchvision torchaudio  # Colab ê¸°ë³¸ ë²„ì „ ì—…ê·¸ë ˆì´ë“œ ìœ ì§€\n",
    "!pip install -q xformers==0.0.29.post1 diffusers==0.26.3 transformers==4.41.1 accelerate==0.30.1 safetensors==0.4.2 bitsandbytes==0.43.1 peft==0.10.0 huggingface_hub==0.25.1 gradio==4.24.0\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()  # ğŸ¤— Hugging Face ë¡œê·¸ì¸ (í† í° í•„ìš”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056413f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [2] Hugging Face Datasetì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ===\n",
    "!git clone https://huggingface.co/datasets/sun2141/lom-cushion-images\n",
    "\n",
    "from pathlib import Path\n",
    "image_dir = Path(\"lom-cushion-images/images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [3] ë°ì´í„°ì…‹ ì¤€ë¹„ ===\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "caption_file = Path(\"lom-cushion-images/prompts/image_caption.csv\")\n",
    "captions_df = pd.read_csv(caption_file)\n",
    "\n",
    "class CushionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir):\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(self.image_dir / row[\"filename\"]).convert(\"RGB\").resize((512, 512))\n",
    "        image_np = np.array(image)\n",
    "        image_tensor = torch.tensor(image_np).permute(2, 0, 1).float() / 255.0\n",
    "        return image_tensor, row[\"prompt\"]\n",
    "\n",
    "train_dataset = CushionDataset(captions_df, image_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [4] ëª¨ë¸ ì¤€ë¹„ ë° LoRA í•™ìŠµ ===\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(base_model, torch_dtype=torch.float16)\n",
    "\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, target_modules=[\"attn2.to_q\", \"attn2.to_k\", \"attn2.to_v\", \"attn2.to_out.0\"])\n",
    "model = get_peft_model(pipeline.unet, lora_config)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for images, prompts in train_loader:\n",
    "        loss = model(images).loss  # ì‹¤ì œë¡œëŠ” LoRAìš© loss í•¨ìˆ˜ í•„ìš” (ë‹¨ìˆœí™”ëœ ì˜ˆì‹œ)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [5] Hugging Face ì—…ë¡œë“œ ===\n",
    "model.save_pretrained(\"./lora-cushion\")\n",
    "!huggingface-cli upload ./lora-cushion \"sun2141/lora-cushion\" --repo-type model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [6] Gradio ì´ë¯¸ì§€ ìƒì„± ===\n",
    "import gradio as gr\n",
    "\n",
    "def generate(prompt):\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\"sun2141/lora-cushion\", torch_dtype=torch.float16)\n",
    "    return pipe(prompt).images[0]\n",
    "\n",
    "gr.Interface(fn=generate, inputs=\"text\", outputs=\"image\").launch(share=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
