{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9886db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ LOM Cushion LoRA Trainer (Colab 노트북)\n",
    "\n",
    "# === [1] 환경설정 ===\n",
    "# Colab 기본 torch==2.6.0, torchvision==0.21.0, torchaudio==2.6.0 유지\n",
    "!pip install -U torch torchvision torchaudio  # Colab 기본 버전 업그레이드 유지\n",
    "!pip install -q xformers==0.0.29.post1 diffusers==0.26.3 transformers==4.41.1 accelerate==0.30.1 safetensors==0.4.2 bitsandbytes==0.43.1 peft==0.10.0 huggingface_hub==0.25.1 gradio==4.24.0\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()  # 🤗 Hugging Face 로그인 (토큰 필요)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056413f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [2] Hugging Face Dataset에서 이미지 다운로드 ===\n",
    "!git clone https://huggingface.co/datasets/sun2141/lom-cushion-images\n",
    "\n",
    "from pathlib import Path\n",
    "image_dir = Path(\"lom-cushion-images/images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [3] 데이터셋 준비 ===\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "caption_file = Path(\"lom-cushion-images/prompts/image_caption.csv\")\n",
    "captions_df = pd.read_csv(caption_file)\n",
    "\n",
    "class CushionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir):\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(self.image_dir / row[\"filename\"]).convert(\"RGB\").resize((512, 512))\n",
    "        image_np = np.array(image)\n",
    "        image_tensor = torch.tensor(image_np).permute(2, 0, 1).float() / 255.0\n",
    "        return image_tensor, row[\"prompt\"]\n",
    "\n",
    "train_dataset = CushionDataset(captions_df, image_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [4] 모델 준비 및 LoRA 학습 ===\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(base_model, torch_dtype=torch.float16)\n",
    "\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, target_modules=[\"attn2.to_q\", \"attn2.to_k\", \"attn2.to_v\", \"attn2.to_out.0\"])\n",
    "model = get_peft_model(pipeline.unet, lora_config)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for images, prompts in train_loader:\n",
    "        loss = model(images).loss  # 실제로는 LoRA용 loss 함수 필요 (단순화된 예시)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [5] Hugging Face 업로드 ===\n",
    "model.save_pretrained(\"./lora-cushion\")\n",
    "!huggingface-cli upload ./lora-cushion \"sun2141/lora-cushion\" --repo-type model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === [6] Gradio 이미지 생성 ===\n",
    "import gradio as gr\n",
    "\n",
    "def generate(prompt):\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\"sun2141/lora-cushion\", torch_dtype=torch.float16)\n",
    "    return pipe(prompt).images[0]\n",
    "\n",
    "gr.Interface(fn=generate, inputs=\"text\", outputs=\"image\").launch(share=True)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
